1. Can you share an example of how you improved the performance (latency or throughput) of a Java application? What was the measurable impact of your optimizations, and what specific tools or techniques did you leverage to achieve those results?
I worked on a Java-based order processing microservice that was experiencing high latency and struggling with throughput during peak business hours. The P95 response time for order creation was exceeding 2 seconds, and we were seeing an increase in timeout errors, impacting our ability to scale.

Task: My task was to identify the bottlenecks and implement optimizations to reduce latency to under 500ms for P95 and increase the sustainable throughput by at least 50%.

Action:

Diagnosis:

I started by using our APM tool, Dynatrace, to get an overview of transaction traces. This highlighted that a significant portion of the time was spent in database interactions and internal business logic computations.
Next, I used VisualVM (and occasionally JProfiler on a staging environment) to profile the application under simulated load. CPU profiling pointed towards excessive object creation in a specific module responsible for validating order items and calculating discounts. Memory profiling showed frequent minor garbage collection cycles.
Detailed logging with timing for specific code sections also helped pinpoint slow database queries.
Optimization Techniques Leveraged:

Database Query Optimization: I identified several N+1 query patterns. I refactored these by using batch fetching and optimizing JPA queries to fetch related entities eagerly where appropriate. I also worked with the DBA to add a couple of missing indexes on frequently queried columns.
Caching: For product details and pricing rules, which were read frequently but updated infrequently, I implemented a Caffeine cache as an in-memory cache. This significantly reduced database calls for these common lookups.
Code Refactoring for Object Allocation: In the order validation module, I refactored the logic to reuse objects where possible and used more primitive types instead of wrapper objects in performance-critical loops. I also switched to using StringBuilder for string concatenations in loops instead of +.
Connection Pooling: We reviewed and tuned the HikariCP database connection pool settings to ensure we weren’t bottlenecked by connection acquisition time under load.
Measurable Impact & Results:

After implementing these changes and verifying with load tests using JMeter, we achieved a reduction in P95 latency for order creation from over 2 seconds to approximately 350ms.
The sustainable throughput of the service increased by nearly 70%, allowing us to handle peak loads comfortably.
We also observed a reduction in minor GC pause times by about 30% and a significant decrease in timeout errors reported in our monitoring dashboards.
This iterative process of profiling, implementing changes, and re-testing was key to achieving these results.

=========================================================================================================
2. What’s your strategy for identifying and fixing memory leaks in Java? Could you outline the tools and techniques you employ for root cause analysis?
My strategy for identifying memory leaks in Java starts with monitoring heap usage using tools like JVisualVM or an APM. If I notice abnormal memory growth or frequent GC, I capture heap dumps and analyze them with Eclipse MAT to find objects with large retained sizes and trace their references.

I look for common causes like static references, unclosed resources, or growing collections. Once I identify the root cause in the code, I fix it — such as clearing collections or properly closing resources — and then verify the solution by monitoring memory usage again.

=========================================================================================================
3. How have you implemented custom thread management in Java? Why not use standard executors?
I have implemented custom thread management in Java in scenarios where the standard ExecutorService or thread pools did not meet specific application requirements. For example, in a real-time data processing system, we needed to prioritize certain high-importance tasks over others, enforce strict limits on the task queue size, and apply custom logic when the queue was full—such as logging, alerting, or dropping low-priority tasks.

To achieve this, I designed a custom thread pool by extending ThreadPoolExecutor and overriding its methods. This allowed me to:

Prioritize Tasks: I used a priority queue for the task queue, so higher-priority tasks were always executed first.
Custom Rejection Handling: I implemented a custom RejectedExecutionHandler to log rejected tasks and trigger alerts, instead of just throwing exceptions or silently discarding them.
Thread Monitoring: I added hooks to monitor thread states, execution times, and resource usage, which helped in debugging and performance tuning.
Graceful Shutdown: I customized the shutdown process to ensure all critical tasks completed before the pool terminated, and resources were released properly.
While standard executors are suitable for most general-purpose concurrency needs, they don’t provide this level of flexibility. Custom thread management is necessary when you need fine-grained control over scheduling, prioritization, resource allocation, or error handling that goes beyond the capabilities of the built-in executors.

=========================================================================================================
4. How would you structure a microservice in Java for observability and fault tolerance?
To structure a Java microservice for observability and fault tolerance, I would:

Observability:
-Logging: Use structured, centralized logging (e.g., with SLF4J + Logback/Log4j2) and include trace IDs for correlation.
-Metrics: Expose application and system metrics (like request counts, latencies, error rates) using libraries such as Micrometer, exporting to Prometheus or similar.
-Distributed Tracing: Integrate tracing (e.g., OpenTelemetry or Spring Cloud Sleuth) to track requests across services.
-Health Checks: Implement readiness and liveness endpoints (e.g., /health) for monitoring and orchestration.

Fault Tolerance:
-Timeouts: Set timeouts on all external calls to avoid hanging threads.
-Retries: Use libraries like Resilience4j or Spring Retry for controlled retries on transient failures.
-Circuit Breakers: Implement circuit breakers (e.g., with Resilience4j) to prevent cascading failures.
-Bulkheads: Isolate resources (e.g., thread pools) to limit the impact of failures.
-Fallbacks: Provide fallback logic for critical operations.
By combining these patterns and tools, the microservice becomes observable for monitoring and resilient against failures.

=========================================================================================================
5. In a high-concurrency environment, how do you ensure data consistency using Java’s concurrency primitives?
In a high-concurrency environment, I ensure data consistency in Java by using appropriate concurrency primitives based on the scenario:

Synchronized blocks or methods to provide mutual exclusion when updating shared mutable state.
Locks (like ReentrantLock or ReadWriteLock) for more advanced locking strategies, such as allowing multiple readers but only one writer.
Atomic variables (AtomicInteger, AtomicReference, etc.) for lock-free, thread-safe updates to single variables.
Concurrent collections (like ConcurrentHashMap, CopyOnWriteArrayList) to safely manage shared data structures without explicit locking.
Volatile variables for visibility guarantees when simple state flags are shared between threads.
I also minimize the scope of critical sections and prefer immutability where possible to reduce contention and the risk of race conditions. 
For complex scenarios, I may use higher-level constructs like StampedLock or Semaphore to control access and ensure consistency.

=========================================================================================================
6. Describe the internals of how garbage collection impacted an SLA in one of your systems. How did you tune it?
In one of my previous systems, we had strict SLAs for API response times, but we noticed periodic latency spikes. 
After investigation, we found that Java’s garbage collector was causing long pause times, especially during full GC cycles, which directly impacted our SLA compliance.

To address this, I analyzed GC logs and observed that the default GC (Parallel GC) wasn’t optimal for our low-latency needs. 
I switched to the G1 garbage collector, which is designed for predictable pause times. 
I then tuned JVM parameters — such as setting -XX:MaxGCPauseMillis to target shorter pauses, adjusting heap sizes, and monitoring with tools like VisualVM and GC log analyzers.

After tuning, GC pause times dropped significantly, and our API response times stabilized, helping us consistently meet our SLA targets.

=========================================================================================================
7. Have you implemented a reactive system in Java (using Project Reactor or RxJava)? What challenges did you face?
Yes, I have implemented reactive systems in Java using Project Reactor. One project involved building a real-time event processing pipeline where we needed to handle thousands of concurrent data streams efficiently.

Challenges I faced included:

-Debugging complexity: Reactive code is more difficult to debug due to its asynchronous and non-blocking nature. 
I used tools like reactor-tools and added extensive logging to trace data flows.

-Backpressure management: Ensuring the system handled backpressure correctly was critical to avoid overwhelming downstream services. 
I had to carefully design publishers and subscribers to respect demand signals.

-Error handling: Propagating and handling errors in a reactive stream required a different approach compared to imperative code, 
so I used operators like onErrorResume and retry.

-Integration with legacy blocking APIs: Sometimes, I had to wrap blocking calls using Schedulers.boundedElastic() to prevent blocking the main event loop.

Despite these challenges, the reactive approach improved our system’s scalability and resource utilization.

=========================================================================================================
8. When would you use CompletableFuture over reactive streams or vice versa? Describe a real use case.
I would use CompletableFuture for handling a small number of asynchronous tasks or when composing a few async operations, 
especially if the workflow is simple and doesn’t require advanced features like backpressure or stream processing. 
For example, I used CompletableFuture to asynchronously fetch data from two microservices, combine the results, and return a response in a REST API
    —since the flow was straightforward and didn’t involve continuous data streams.

On the other hand, 
I’d use reactive streams (like Project Reactor or RxJava) when dealing with asynchronous processing of large or unbounded streams of data, 
or when I need features like backpressure, event-driven pipelines, or complex transformations. 
For instance, I used Reactor to build a real-time event processing system that ingested, transformed, and routed thousands of events per second, 
where managing flow control and resource usage was critical.

In summary:

Use CompletableFuture for simple, finite async workflows.
Use reactive streams for complex, high-throughput, or continuous data processing with advanced requirements.

=========================================================================================================
9. Describe how you’ve handled serialization challenges across services in Java (e.g., using Jackson, Avro, Protobuf).
I’ve handled serialization challenges across services in Java by standardizing on a serialization format and ensuring schema compatibility. 
For REST APIs, I’ve used Jackson for JSON serialization, carefully managing versioning with custom serializers/deserializers and annotations to handle backward compatibility when fields change.

For high-performance or cross-language communication, I’ve used Avro and Protobuf. 
With Avro, I maintained schemas in a central repository and used schema evolution features to support changes without breaking consumers. 
With Protobuf, I enforced strict versioning and used optional fields to maintain compatibility. 
I also set up automated tests to validate serialization and deserialization across service boundaries, ensuring data integrity and smooth upgrades.

=========================================================================================================
10. In a monolith-to-microservices migration, how did you handle shared business logic or DTOs in Java?
In a monolith-to-microservices migration, I handled shared business logic and DTOs in Java by extracting them into separate, versioned libraries or modules. 
These libraries were published to a private Maven repository, so each microservice could include them as dependencies. 
This ensured consistency and reduced code duplication.

For business logic, I kept only truly reusable, stateless utilities in the shared library, 
while service-specific logic stayed within each microservice. 

For DTOs, I versioned the shared models and used backward-compatible changes to avoid breaking services. 
Over time, as microservices evolved independently, I encouraged teams to minimize shared dependencies to reduce coupling and promote autonomy.