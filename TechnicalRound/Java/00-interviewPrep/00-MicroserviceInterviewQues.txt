AWS API gateway working
Microservices communication to each others
Microservices design patterns
central logging in microservice
AWS cloud watch
AWS lambda functions
AWS EC2
AWS api security

Apache kafka testing -> Pact

L1 vs L2 vs L3 support

why no arg constructor is required in spring bean
circular dependency





------------------------------

# How to deal with the performance issues occured in one of microservice in AWS cloud platform
-> Dealing with performance issues in a microservice running on the AWS cloud platform requires a systematic approach to identify 
   the root causes and implement necessary improvements. Here's a step-by-step guide to help you tackle performance issues effectively:

1. **Monitoring and Alerts:**
   -> Set up comprehensive monitoring and logging for your microservice using AWS CloudWatch, AWS X-Ray, or other monitoring tools. 
   Establish relevant performance metrics and configure alerts to notify you when performance thresholds are breached.

2. **Identify the Bottleneck:**
   -> Analyze the monitoring data to identify the specific components or areas of your microservice that are causing performance degradation. 
   It could be CPU utilization, memory usage, database queries, network latency, or any other bottleneck.

3. **Optimize Code:**
   -> Review and optimize the code of your microservice. 
   Look for inefficient algorithms, redundant computations, or resource-intensive operations that can be improved.

4. **Scale Vertically or Horizontally:**
   -> Depending on the bottleneck, consider scaling your microservice either vertically (upgrading instance size) 
   or horizontally (adding more instances). AWS Auto Scaling can help with dynamic scaling based on demand.

5. **Database Optimization:**
   -> If your microservice relies on a database, optimize the database queries, add appropriate indexes, and consider caching strategies to reduce the load on the database.

6. **Caching:**
   -> Implement caching for frequently accessed data using services like AWS ElastiCache or AWS Redis. 
   Caching can significantly reduce response times and alleviate the load on your microservice.

7. **Content Delivery Network (CDN):**
   -> If your microservice serves static content, consider using AWS CloudFront or other CDN services to cache and deliver content from edge locations closer to your users, reducing latency.

8. **Connection Pooling:**
   -> If your microservice connects to databases or external services, use connection pooling to manage and reuse connections efficiently, reducing connection overhead.

9. **Request/Response Optimization:**
   -> Minimize the size of request/response payloads and avoid unnecessary data transfers. 
   Use compression and efficient data formats when possible.

10. **Database Sharding:**
    -> If your microservice handles large amounts of data, consider database sharding to distribute the data across multiple database instances, improving performance.

11. **Load Testing:**
    -> Conduct load testing on your microservice to identify its performance limits and understand how it behaves under various levels of stress. 
    Tools like Apache JMeter or Gatling can be used for load testing.

12. **Infrastructure Review:**
    -> Review your microservice's infrastructure on AWS. 
    Ensure that you are using appropriate instance types, storage, and network configurations.

13. **Cost Optimization:**
    -> Be mindful of the cost implications of any performance improvement measures you implement. 
    Balance performance enhancements with cost-effectiveness.

14. **Continuous Monitoring and Iteration:**
    -> Performance tuning is an ongoing process. 
    Continuously monitor your microservice's performance, analyze the results, and iteratively improve your system as needed.

Remember that performance issues can have multiple underlying causes, so it's essential to be methodical and data-driven in your approach. 
Additionally, consider leveraging AWS Well-Architected Framework principles to build and maintain a high-performing, reliable, and cost-efficient microservice architecture on AWS.


---------------------------
# How Microservices communication to each others
Microservices communicate with each other through various communication mechanisms to exchange data and coordinate their actions. 
The most common communication patterns include:

1. **HTTP/RESTful APIs:
Microservices can expose HTTP endpoints and communicate using RESTful APIs. 
This is one of the most popular communication patterns in microservices architecture. 
Services can make HTTP requests (GET, POST, PUT, DELETE, etc.) to interact with each other and transfer data in JSON or XML format.

2. **Messaging/Message Queues:
Microservices can communicate asynchronously using messaging systems such as Apache Kafka, RabbitMQ, or Amazon SQS. 
Messages are sent to queues or topics, and other services can consume these messages as needed.

3. **gRPC:** 
gRPC is a modern, high-performance RPC (Remote Procedure Call) framework developed by Google. 
It uses Protocol Buffers for efficient data serialization and supports bidirectional streaming, making it ideal for microservices communication.

4. **GraphQL:** 
GraphQL is a query language for APIs that allows clients to request specific data from a microservice, providing more flexibility compared to traditional REST APIs.

5. **Service Mesh:** 
A service mesh, like Istio or Linkerd, is a dedicated infrastructure layer that handles communication between microservices transparently. 
It provides features like service discovery, load balancing, traffic management, and security.

6. **Event-Driven Architecture (EDA):** 
Microservices can communicate through events using patterns like publish/subscribe or event sourcing. 
Events represent state changes or significant occurrences in the system, and other services can react to these events accordingly.

7. **WebSockets:** 
WebSockets enable bidirectional communication between microservices and clients, allowing real-time data streaming and push notifications.

8. **RSocket:** 
RSocket is a reactive, binary, and multiplexed protocol suitable for communication in reactive systems and microservices.

9. **REST Hooks:** 
REST hooks enable event-driven communication in RESTful APIs. Clients can register callback URLs with a microservice, and when specific events occur, the microservice sends notifications to these registered URLs.

10. **Direct Database Access:** 
In some cases, microservices might interact with shared databases, though this approach is generally discouraged due to potential tight coupling and data ownership issues.

The choice of communication mechanism depends on various factors, including the nature of the data being exchanged, latency requirements, scalability needs, and the complexity of interactions between microservices. It's common to use a combination of communication patterns in a microservices architecture to address different use cases efficiently. Additionally, adopting API gateways and service discovery mechanisms can help manage and abstract the complexities of microservices communication.


---------------------------
#Central Logging in Microservice - ELK (Elastic-Search, Logstash, Kibana)
The ELK Stack began as a collection of three open-source products — Elasticsearch, Logstash, and Kibana 
— all developed, managed and maintained by Elastic. 
The introduction and subsequent addition of Beats turned the stack into a four legged project.

"Elasticsearch" is a full-text search and analysis engine, based on the Apache Lucene open source search engine. 

"Logstash" is a log aggregator that collects data from various input sources, executes different transformations and enhancements and 
then ships the data to various supported output destinations. 
It's important to know that many modern implementations of ELK do not include Logstash. 
To replace its log processing capabilities, most turn to lightweight alternatives like Fluentd, which can also collect logs from data sources and forward them to Elasticsearch. 

"Kibana" is a visualization layer that works on top of Elasticsearch, providing users with the ability to analyze and visualize the data. 
And last but not least — Beats are lightweight agents that are installed on edge hosts to collect different types of data for forwarding into the stack.

Together, these different components are most commonly used for monitoring, troubleshooting and securing IT environments 
(though there are many more use cases for the ELK Stack such as business intelligence and web analytics). 
Beats and (formerly) Logstash take care of data collection and processing, Elasticsearch indexes and stores the data, and Kibana provides a user interface for querying the data and visualizing it.


















---------------------------










































